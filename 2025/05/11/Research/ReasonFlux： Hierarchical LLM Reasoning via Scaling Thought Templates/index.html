<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>ReasonFlux阅读 - Pluto&#039;s Blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Pluto&#039;s Blog"><meta name="msapplication-TileImage" content="https://cdn.jsdelivr.net/gh/1-pluto1/blog_imgs/b_0b65080deefa163507d3aa4c6a7a5e07.jpg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Pluto&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="单位： Princeton University， Peking UniversityCode: https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;Gen-Verse&amp;#x2F;ReasonFlux基座模型： Qwen2.5-32B-Instruct原文地址：https:&amp;#x2F;&amp;#x2F;arxiv.org&amp;#x2F;pdf&amp;#x2F;2502.06772显卡：8 * NVIDIA A100 GPU"><meta property="og:type" content="article"><meta property="og:title" content="ReasonFlux阅读"><meta property="og:url" content="http://example.com/2025/05/11/Research/ReasonFlux%EF%BC%9A%20Hierarchical%20LLM%20Reasoning%20via%20Scaling%20Thought%20Templates/"><meta property="og:site_name" content="Pluto&#039;s Blog"><meta property="og:description" content="单位： Princeton University， Peking UniversityCode: https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;Gen-Verse&amp;#x2F;ReasonFlux基座模型： Qwen2.5-32B-Instruct原文地址：https:&amp;#x2F;&amp;#x2F;arxiv.org&amp;#x2F;pdf&amp;#x2F;2502.06772显卡：8 * NVIDIA A100 GPU"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://github.com/Gen-Verse/ReasonFlux/raw/main/figs/image.png"><meta property="article:published_time" content="2025-05-10T20:35:40.000Z"><meta property="article:modified_time" content="2025-05-31T13:51:44.042Z"><meta property="article:author" content="Pluto"><meta property="article:tag" content="NLP"><meta property="article:tag" content="LLM"><meta property="article:tag" content="ReasoningModel"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://github.com/Gen-Verse/ReasonFlux/raw/main/figs/image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://example.com/2025/05/11/Research/ReasonFlux%EF%BC%9A%20Hierarchical%20LLM%20Reasoning%20via%20Scaling%20Thought%20Templates/"},"headline":"Pluto's Blog","image":["https://github.com/Gen-Verse/ReasonFlux/raw/main/figs/image.png"],"datePublished":"2025-05-10T20:35:40.000Z","dateModified":"2025-05-31T13:51:44.042Z","author":{"@type":"Person","name":"Pluto"},"publisher":{"@type":"Organization","logo":{"@type":"ImageObject"}},"description":"单位： Princeton University， Peking UniversityCode: https:&#x2F;&#x2F;github.com&#x2F;Gen-Verse&#x2F;ReasonFlux基座模型： Qwen2.5-32B-Instruct原文地址：https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2502.06772显卡：8 * NVIDIA A100 GPU"}</script><link rel="canonical" href="http://example.com/2025/05/11/Research/ReasonFlux%EF%BC%9A%20Hierarchical%20LLM%20Reasoning%20via%20Scaling%20Thought%20Templates/"><link rel="icon" href="https://cdn.jsdelivr.net/gh/1-pluto1/blog_imgs/b_0b65080deefa163507d3aa4c6a7a5e07.jpg"><meta name="referrer" content="no-referrer-when-downgrade"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/6.0.0/css/all.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/highlight.js/11.7.0/styles/atom-one-light.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.12.0/css/all.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css?family=Ubuntu:400,600|Source+Code+Pro|Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Microsoft YaHei:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&amp;amp;subset=latin,latin-ext|Inconsolata|Itim|Lobster.css"><script src="https://cdnjs.loli.net/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="/js/globalUtils.js"></script><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/lightgallery/1.10.0/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.8.1/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdnjs.loli.net/ajax/libs/pace/1.2.4/pace.min.js"></script><script async="" referrerpolicy="no-referrer" src="//cdn.jsdelivr.net/npm/leancloud-storage@3/dist/av-min.js"></script><script src="//unpkg.com/valine/dist/Valine.min.js"></script><script src="/js/md5.min.js"></script><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head><body class="is-3-column has-navbar-fixed-top"><nav class="navbar navbar-main is-fixed-top"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="https://cdn.jsdelivr.net/gh/1-pluto1/blog_imgs/b_0b65080deefa163507d3aa4c6a7a5e07.jpg" alt="Pluto&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/1-pluto1"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a><a class="navbar-item" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a></div></div></div></nav><script type="text/javascript" src="/js/theme-setting.js"></script><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><!--!--><div class="card"><div class="card-image"><span class="image is-7by3"><img class="fill" src="https://github.com/Gen-Verse/ReasonFlux/raw/main/figs/image.png" alt="ReasonFlux阅读"></span></div><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2025-05-11  <a class="commentCountImg" href="/2025/05/11/Research/ReasonFlux%EF%BC%9A%20Hierarchical%20LLM%20Reasoning%20via%20Scaling%20Thought%20Templates/#comment-container"><span class="display-none-class">/2025/05/11/Research/ReasonFlux： Hierarchical LLM Reasoning via Scaling Thought Templates/</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="acf9313e0c59c883250c034a2fc297f2">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>44 分钟  <i class="fas fa-pencil-alt"> </i>6.6 k</span><span class="level-item" id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv">0</span>次访问</span></div></div><h1 class="title is-3 is-size-4-mobile">ReasonFlux阅读</h1><div class="content"><p>单位： Princeton University， Peking University<br>Code: <a target="_blank" rel="noopener" href="https://github.com/Gen-Verse/ReasonFlux">https://github.com/Gen-Verse/ReasonFlux</a><br>基座模型： Qwen2.5-32B-Instruct<br>原文地址：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2502.06772">https://arxiv.org/pdf/2502.06772</a><br>显卡：8 * NVIDIA A100 GPU</p>
<span id="more"></span>


<p>单位： Princeton University， Peking University<br>Code: <a target="_blank" rel="noopener" href="https://github.com/Gen-Verse/ReasonFlux">https://github.com/Gen-Verse/ReasonFlux</a><br>基座模型： Qwen2.5-32B-Instruct<br>原文地址：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2502.06772">https://arxiv.org/pdf/2502.06772</a><br>显卡：8 * NVIDIA A100 GPU</p>
<p>备注：和之前的SUPERCORRECT、是同一位作者，这也是SUPERCORRECT的一个继承工作。</p>
<p><img src="https://cdn.jsdelivr.net/gh/1-pluto1/blog_imgs/20250511125217403.png" alt="image.png"></p>
<p>摘要： ReasonFlux提出，通过扩展思维模板的分层LLM推理能够有效优化推理搜索空间，并在数学推理能力上超越强大的LLM模型。使用8 * NVIDIA A100 GPU训练了ReasonFlux-32B模型，显著提升了数学推理能力，达到了最先进的水平。</p>
<h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>大型语言模型（LLMs）最近取得了显著进展，展示了在解决复杂推理任务方面的卓越能力，甚至在某些特定领域超越了人类专家。例如，OpenAI的O1（Jaech等，2024）、Google的Gemini-2.0（Team等，2024）、DeepSeek-V3（Liu等，2024b）和Qwen-QwQ（Team，2024a）等模型处于这一进展的前沿，它们通过更慢、更慎重的思维过程来模拟人类推理。这些模型利用增加的推理时间来提高推理准确性。尽管它们已经解锁了显著的性能提升，但更复杂的任务，如AIME中的数学问题解决、OlympiadBench（He等，2024）和LiveCodeBench（Jain等，2024）中的代码，这些任务需要在庞大的解空间中进行更细粒度的搜索，并对每个复杂的推理步骤进行更精细的思考，因此仍然构成了重大挑战。</p>
<p>后续研究集中于通过推理时策略来增强大型语言模型在复杂问题上的推理能力。这些策略可以分为两类：<strong>刻意搜索</strong>和<strong>奖励模型引导</strong>的方法。刻意搜索方法，如<strong>思维树（Tree of Thoughts, ToT）</strong>（Yao et al., 2024）和<strong>思维图（Graph of Thoughts, GoT）</strong>（Besta et al., 2024），允许大语言模型（LLMs）探索多种推理路径并自我评估选择，以找到最优的推理轨迹。奖励模型引导的方法则利用奖励模型来评估推理步骤的质量。<strong>最佳N选一（Best-of-N）<strong><strong><strong>方法利用</strong></strong></strong>结果奖励模型（Outcome Reward Model, ORM）<strong><strong><strong>在多个候选路径中找到最优的推理路径，而</strong></strong></strong>过程奖励模型（Process Reward Models, PRMs）</strong>（Lightman et al., 2023; Luo et al., 2024; Wang et al., 2024）则通过奖励高概率的中间步骤，引导模型走向有潜力的路径。在此基础上，<strong>蒙特卡洛树搜索（Monte Carlo Tree Search, MCTS）</strong>（Zhang et al., 2024a; Qi et al., 2024）采用细粒度的搜索，将任务分解为更简单的步骤，并使用PRMs在基于树的搜索空间中指导动作选择。然而，这些方法通常会产生较高的计算成本，尤其是在推理步骤较多或搜索空间较大的情况下，这主要是由于采样的随机性，阻碍了高效识别最优推理轨迹。此外，它们依赖于手动设计的搜索策略和实例&#x2F;步骤级别的奖励，限制了其在多样化和复杂推理任务中的泛化能力。本质上，这些方法在推理扩展时难以有效平衡<strong>探索与利用</strong>的权衡。这凸显了对一种更高效且可泛化的推理扩展方法的需求，该方法能够在无需大量手动干预的情况下增强推理能力，并提供更原则性的搜索策略。</p>
<p>为了实现更高效和精确的推理路径搜索，一种可行的方法是使用检索增强生成（Retrieval-Augmented Generation, RAG）。最近的思维缓冲（Buffer of Thought, BoT）（Yang et al., 2024b）构建了一个元缓冲，用于存储从各种问题解决过程中提炼出的信息丰富、高层次的思维，并自适应地检索和实例化与每个特定任务相关的思维模板。SuperCorrect（Yang et al., 2024c）进一步利用高层次和详细的思维模板来增强小型语言模型（LLMs）的推理能力。尽管取得了显著改进，这种基于模板的推理方法在应用于复杂推理任务时仍可能面临挑战。因为复杂问题通常需要整合多个模板或多样化的检索信息，而当前的方法在这方面仍难以有效应对。</p>
<p>为此，我们引入了ReasonFlux，这是一种新颖的分层LLM推理框架，通过在推理时自动检索相关的高级思维模板来配置最优的思维模板轨迹，从而在复杂推理任务上实现卓越性能，甚至超越了OpenAI的o1-preview和o1-mini模型。具体来说，我们首先构建了一个结构化的模板库，其中包含500个有用的压缩思维模板，以便于高效检索和适配。我们不再优化一个长的CoT（Chain-of-Thought）轨迹，而是对一系列高级思维模板进行分层强化学习，优化基础LLM以从多个模板中学习最优的思维模板轨迹，并引导推理LLM解决一系列更简单的子问题。最后，我们通过自适应缩放思维模板开发了一种新的推理缩放系统。这种分层推理范式使ReasonFlux能够简化推理路径的搜索，并通过为每个子问题动态选择最合适的高级模板来增强复杂问题的推理能力。我们的自动模板缩放使ReasonFlux能够有效地实现更好的探索与利用的权衡，从而带来更稳健和高效的问题解决过程。通过这些创新，ReasonFlux为增强LLM的复杂推理能力提供了一个更高效、可泛化和可扩展的解决方案。最后，我们将我们的贡献总结如下：<br><img src="https://cdn.jsdelivr.net/gh/1-pluto1/blog_imgs/20250511125240630.png" alt="image.png"></p>
<ol>
<li><p>我们引入了ReasonFlux（如图1所示），这是一个分层次的LLM推理框架，显著增强了复杂推理能力，在具有挑战性的MATH和AIME基准测试中（如表2所示）超越了SOTA模型，如o1-preview和DeepSeek-V3。</p>
</li>
<li><p>我们提出了一个结构化和紧凑的模板库，其中包含从具有挑战性的数学问题中精选的约500个思维模板。该库有助于高效检索和适配相关的高级思维模板，用于一系列详细的推理步骤。</p>
</li>
<li><p>我们开发了基于一系列高级思维模板的分层次强化学习，使LLM能够为一系列较简单的子问题生成最优的思维模板轨迹，从而有效简化推理路径的搜索空间。</p>
</li>
<li><p>我们设计了一个新的推理扩展系统（如图2所示），通过自适应扩展思维模板进行分层次推理。该系统使ReasonFlux能够在推理时动态检索一系列高级模板，并自适应地执行实例化推理，从而在探索与利用之间实现更好的平衡，以进行稳健且高效的问题解决。</p>
</li>
</ol>
<h3 id="Related-Work-and-Discussions"><a href="#Related-Work-and-Discussions" class="headerlink" title="Related Work and Discussions"></a>Related Work and Discussions</h3><p><strong>从语言模型的偏好中学习</strong> 偏好学习对于将大型语言模型（LLMs）与人类的期望和感知对齐至关重要。最初的方法基于预训练和监督微调（SFT），并在从人类&#x2F;人工智能反馈的强化学习（RLHF&#x2F;RLAIF）框架中采用了PPO（Schulman等，2017；Christiano等，2017；Ouyang等，2022；Xie等，2024）。这些方法通常涉及在偏好对上训练奖励模型，随后优化LLM以最大化学习到的奖励。然而，PPO的不稳定性和低效性促使了替代方法的出现，如DPO（Rafailov等，2024），它直接从成对偏好数据中优化策略。后续研究解决了各种挑战。ORPO（Hong等，2024）将对齐整合到SFT中，KTO（Ethayarajh等，2024）利用点数据，简化了数据获取过程。其他努力集中在更细粒度的优化上，如Step-DPO（Lai等，2024）和Cross-DPO（Yang等，2024c），它们针对中间推理或反思步骤。SPO（Swamy等，2024）采用博弈论概念来解决非传递性偏好，而Multi-turn DPO（Shi等，2024）将优化扩展到对话中。然而，现有方法通常依赖于实例或步骤级别的奖励单位，可能无法捕捉和奖励人类问题解决过程中固有的高级认知过程。为此，我们引入了基于层次化RL的优化，这是一种新颖的偏好学习方法，鼓励模型配置一系列高级思维模板，以处理复杂问题的多样化子任务，从而在LLMs中促进更类似人类的问题解决策略。</p>
<p><strong>检索增强生成语言模型</strong> 检索增强生成语言模型（Retrieval-Augmented Language Models, RALMs）已成为一种有效的方法，用于减少幻觉并提升大语言模型（LLMs）的事实准确性（Asai等，2023；Mialon等，2023；Shi等，2023；Gao等，2023；Zhao等，2024）。通过从大规模外部知识源（Borgeaud等，2022）中检索相关文档以指导响应生成，RALMs在问答任务中展现出卓越的性能，且通常比传统LLMs所需的参数更少（Mialon等，2023）。其多功能性在多样化任务中的成功应用进一步得到验证，包括多模态生成和生物医学应用（Yasunaga等，2023；Izacard等，2023；Wang等，2022；Zhao等，2024；Borgeaud等，2022；Yang等，2023）。然而，RALMs在复杂推理任务（如数学和代码）中面临挑战，其中通过标准嵌入相似性搜索检索相关指南或模板较为困难。尽管RAFT（Zhang等，2024c）等方法试图通过提高检索相关性来解决这一问题，但其有效性随着文档长度的增加而逐渐降低。为了克服这些限制，我们设计了一个结构化和紧凑的模板库，旨在高效且准确地检索，特别针对复杂的推理问题。</p>
<p><strong>大语言模型（LLM）推理中的推理扩展</strong> 大语言模型的自回归特性表明，解决更复杂的问题本质上需要生成更多的标记。早期的工作，如链式思维（CoT，Wei 等，2022），通过提示技术（例如“让我们一步一步思考”）将复杂的推理任务分解为更简单的子问题，从而提升推理性能。在此基础上，树状思维（ToT，Yao 等，2024）和图状思维（GoT，Besta 等，2024）采用不同的数据结构扩展了推理空间，使大语言模型能够探索多种解决路径。最近的研究（Wu 等，2024；Snell 等，2024）形式化了推理扩展规律的概念，探讨了生成额外标记与使用不同推理策略之间的权衡。例如，多数投票和最佳选择方法（Wang 等，2023；Li 等，2023）生成多个候选解，并根据结果中的频率或奖励模型的评估选择最佳解。类似地，使用蒙特卡洛树搜索（MCTS，Zhang 等，2024b；Liu 等，2024c；Choi 等，2023；Zhou 等，2023）的方法通过更大的搜索和计算量来提高准确性。为了提升搜索精度，过程奖励模型（PRMs）被引入以选择高质量的推理路径，研究（Setlur 等，2024；Snell 等，2024；Lightman 等，2023；Luo 等，2024；Wang 等，2024）证明了其在复杂推理任务中的有效性。最近，诸如思维模板（BoT，Yang 等，2024b）等方法利用过去推理过程中的思维模板来引导探索，显著提高了效率。然而，对于这些基于模板的方法，探索与利用的权衡（Tang 等，2024；Setlur 等，2024）仍是一个未解决的挑战。我们的工作通过扩展一种分层的模板增强推理范式来应对这一挑战，在战略性地平衡探索与利用的同时，显著提升了推理准确性，尤其是在复杂任务中。</p>
<h3 id="ReasonFlux-Scaling-Thought-Templates-for-Hierarchical-LLM-Reasoning"><a href="#ReasonFlux-Scaling-Thought-Templates-for-Hierarchical-LLM-Reasoning" class="headerlink" title="ReasonFlux: Scaling Thought Templates for Hierarchical LLM Reasoning"></a>ReasonFlux: Scaling Thought Templates for Hierarchical LLM Reasoning</h3><h4 id="Constructing-Structured-Thought-Template-Library"><a href="#Constructing-Structured-Thought-Template-Library" class="headerlink" title="Constructing Structured Thought Template Library"></a>Constructing Structured Thought Template Library</h4><p>受到人类在解决复杂推理问题时利用外部资源的启发，RAG方法通过使大型语言模型（LLMs）能够从外部来源检索信息来增强其能力（Zhao等，2024）。最近的“思维缓冲区”（BoT）（Yang等，2024b）尝试为LLM推理创建一个高级思维缓冲区，并构建了一个高效的RAG推理系统。尽管BoT拥有一个全面的模板库来解决类似问题，但随着模板规模的增加，它仍然面临可扩展性挑战，这与依赖嵌入相似性来搜索非结构化文本语料库的传统RAG系统相同。</p>
<p>为了解决这一问题，我们的方法专注于构建一个结构化的思维模板库，以实现更精确、有针对性的检索，并缓解可扩展性挑战。为了构建这个库，我们从不同来源精心挑选了广泛且多样化的具有挑战性的数学推理问题，确保模板库的鲁棒性和广泛适用性。我们使用大语言模型（LLM）分析解决方案背后的思维，生成简洁的问题解决策略摘要，并识别常见模式。这一过程产生了一系列高质量、以解决方案为导向的思维模板。库中的每个模板Ti都经过结构化设计，以便高效检索和应用，其中Tnam是模板名称（例如，“√R2 − x2型三角代换”），Ttag是一组用于基于关键词检索的标签（例如，{“三角代换”，“无理函数优化”}），Tdes是对基本原理和适用场景的描述，Tsco定义了范围，指定了它解决的问题类型，Ta是一系列详细的应用步骤{a1, a2, …, ak}，而Texa是一组展示其应用的示例。整个模板库Dtemp是一组上述思维模板的集合：Dtemp &#x3D; {T1, T2, …, Tm} (1)，其中m是模板的总数。在此，我们展示了库中一个思维模板的示例。为了简洁起见，以下示例中的某些字段已简化。更多详细示例请参见附录A。</p>
<p><img src="https://cdn.jsdelivr.net/gh/1-pluto1/blog_imgs/20250511125307375.png" alt="image.png"></p>
<p>通过利用与每个模板相关的元数据，特别是名称（n）和标签（t），可以快速准确地基于关键词或特定问题特征进行检索，从而实现高效的检索。这种结构化的组织方式，结合丰富的元数据，确保了在任何给定问题下，最相关的模板都能迅速可用。</p>
<h4 id="Hierarchical-Reinforcement-Learning-on-Thought-Template-Trajectory"><a href="#Hierarchical-Reinforcement-Learning-on-Thought-Template-Trajectory" class="headerlink" title="Hierarchical Reinforcement Learning on Thought Template Trajectory"></a>Hierarchical Reinforcement Learning on Thought Template Trajectory</h4><p>尽管我们的结构化模板库为推理提供了宝贵的资源，但仍需一种有效的方法来利用该库并选择合适的模板以处理特定问题。为此，我们采用分层强化学习进行训练，最终获得了能够有效规划出问题最优思维模板轨迹的ReasonFlux。我们从库中检索并配置一系列相关模板，协助在特定子问题上实例化这些检索到的模板。ReasonFlux充当经验丰富的导航者，提供最优轨迹（表示为Ttraj），使大语言模型能够将抽象的思维模板实例化为具体的顺序问题解决步骤。</p>
<p>基于结构的微调 我们的分层强化学习过程首先利用结构化模板库Dtemp构建一个知识密集型的训练数据集Dtrain。该数据集包含模板名称Tnam、相关标签Ttag、其基本原理的详细描述Tdes以及其适用范围的清晰界定Tsco的多样化示例，这些信息以元组形式（Tnam, Ttag, Tdes, Tsco）从Dtemp中提取。随后，我们在这个数据集Dtrain上对一个基础大语言模型（LLM）进行微调，该模型记为π。这一过程使模型对库中每个模板的结构、内容和预期用途有了基础理解。微调过程由以下优化目标驱动：</p>
<p><img src="https://cdn.jsdelivr.net/gh/1-pluto1/blog_imgs/20250511125759027.png" alt="image.png"></p>
<p>其中，目标是在给定模板名称Tnam和标签Ttag的情况下，最大化模型生成正确描述Tdes和范围Tsco的可能性。这确保了微调后的模型能够有效地将模板的标识信息（Tnam和Ttag）与其功能方面（Tdes和Tsco）关联起来。微调后，我们将生成的模型记为πstruct。</p>
<p>基于微调的大型语言模型（LLM）πstruct，我们可以进一步增强其能力，为输入问题x规划出一系列高级思维模板（即思维模板轨迹Ttraj），并将每个步骤与库中最相关的模板关联起来。这是通过我们在思维模板轨迹上的偏好学习实现的。具体来说，如图1所示，给定一个输入问题x，πstruct首先分析并抽象出问题的条件信息，识别出涉及的核心数学概念和关系。基于这种抽象表示，导航器πstruct随后配置一个轨迹Ttraj &#x3D; {s1, s2, …, sn}，其中每个si代表推理过程中的一个高级步骤，并与从库中检索出的特定模板名称相关联，该模板可用于解决问题，记为Ti。每个检索到的模板Ti随后会用输入问题x的具体细节进行实例化，并为单独推理的LLM（记为πinf）提供细粒度的指导，以解决问题。</p>
<p>为了衡量给定轨迹的有效性和泛化能力，我们使用一组与原始输入问题x相似的问题Xsim，包括x本身。然后，我们使用沿轨迹Ttraj实例化的模板来指导πinf解决每个问题xi ∈ Xsim。πinf在这些问题上的平均准确率作为轨迹奖励R(Ttraj)。形式上：</p>
<p>$$R(T_{traj}) &#x3D; \frac{1}{|X_{sim}|} \sum_{x_i \in X_{sim}} \text{Acc}(\pi_{inf}(x_i, T_{traj})) \quad (3)$$</p>
<p>其中，$\text{Acc}(\pi_{inf}(x_i, T_{traj}))$表示πinf在轨迹Ttraj指导下解决问题xi的准确率。</p>
<p>这个奖励信号随后用于构建优化对，使我们能够进一步优化导航器πstruct。具体来说，对于每个输入问题x，我们采样多个不同的Ttraj，并利用模板轨迹奖励评估其质量。我们定义优化πstruct的损失函数如下：</p>
<p>$$L_{TTR}(\theta) &#x3D; -\mathbb{E}<em>{(x, (T^+</em>{traj}, T^-<em>{traj})) \sim D</em>{pair}} \left[ \log \sigma \left( \beta \log \frac{\pi_{\theta}(T^+<em>{traj}|x)}{\pi</em>{sft}(T^+<em>{traj}|x)} - \beta \log \frac{\pi</em>{\theta}(T^-<em>{traj}|x)}{\pi</em>{sft}(T^-_{traj}|x)} \right) \right] \quad (4)$$</p>
<p>其中，$D_{pair}$是优化对的数据集。每对包括一个输入问题x和两个轨迹$T^+<em>{traj}$和$T^-</em>{traj}$，其中$R(T^+<em>{traj}) &gt; R(T^-</em>{traj})$。$\pi_{\theta}$表示正在优化的LLM，参数为θ，从πstruct初始化。</p>
<h4 id="Inference-Scaling-with-Scaling-Thought-Templates"><a href="#Inference-Scaling-with-Scaling-Thought-Templates" class="headerlink" title="Inference Scaling with Scaling Thought Templates"></a>Inference Scaling with Scaling Thought Templates</h4><p>在层次化强化学习（RL）过程之后，我们将优化后的导航器πθ称为<strong>ReasonFlux</strong>。然后，我们进一步设计了一种新颖的推理扩展系统，通过利用自动规划的轨迹和动态检索的思维模板来实现。该系统如图2所示，涉及<strong>ReasonFlux</strong>、结构化模板库<strong>Dtemp</strong>和下游推理大语言模型（LLM）<strong>πinf</strong>之间的多轮交互。给定一个输入问题x，<strong>ReasonFlux</strong>的首要任务是分析并提取嵌入在x中的核心数学概念和关系。基于这个抽象表示，记为a(x)，<strong>ReasonFlux</strong>随后配置一个最优模板轨迹T∗ traj。该轨迹表示为一系列步骤T∗ traj &#x3D; {s1∗, s2∗, …, s∗n}，它不是一个僵化的、预定义的路径，而是一个根据输入问题x的具体细节动态生成的计划。轨迹中的每个步骤s∗ i都与一个特定的模板名称Tnam和Ttag相关联，以便高效检索。<strong>ReasonFlux</strong>随后从精心策划的思维模板库<strong>Dtemp</strong>中搜索并检索一组最相关的思维模板。形式上，检索过程可以表示为：</p>
<p>$$\text{Trag} &#x3D; \text{ReasonFlux}({T^i_{\text{nam}}, T^i_{\text{tag}}}^n_{i&#x3D;1}, \text{Dtemp}), \quad (5)$$</p>
<p>其中，Trag &#x3D; {T1, T2, …, Tn}是检索到的n个模板的集合，与配置的轨迹中的步骤数量相等，每个模板都是一个结构化模板。随后，基于T∗ traj和检索到的模板Trag，<strong>ReasonFlux</strong>将指导<strong>πinf</strong>实例化每个步骤s∗ i，并结合相应的模板Ti和问题x中的具体细节，转化为具体的实例化推理步骤sˆi：</p>
<p>$$\hat{s}<em>i &#x3D; \pi</em>{\text{inf}}(x_i, s_i, T_i), \quad (6)$$</p>
<p>其中，每个sˆi是基于相应的s∗ i、Ti和x生成的。<strong>ReasonFlux</strong>和<strong>πinf</strong>之间的交互不是单向的，而是以迭代的方式进行。在获得实例化步骤sˆi后，<strong>ReasonFlux</strong>会对其进行评估和分析，我们将这一调整过程表示为δi &#x3D; ReasonFlux(T∗ traj, sˆi)。基于这一评估结果和分析，<strong>ReasonFlux</strong>决定是否优化轨迹，可能会调整后续步骤，甚至检索替代模板。这种迭代优化可以表示为：</p>
<p>$$T^<em>_{\text{traj}} \leftarrow \text{ReasonFlux}(T^</em>_{\text{traj}}, \delta_i). \quad (7)$$</p>
<p><strong>ReasonFlux</strong>和<strong>πinf</strong>之间的这种迭代反馈机制强调了复杂问题解决中的一个关键方面：规划与执行之间的动态交互。通过分析推理过程中生成的中间结果，<strong>ReasonFlux</strong>获得了有价值的见解，可以为轨迹的调整提供信息。这种优化解决方案路径的能力精确地反映了人类如何通过检查部分结果来发现更高效或更有效的解决方案。此外，中间步骤可能会揭示问题中先前被掩盖的约束或机会，从而允许采用更明智和有针对性的方法。因此，<strong>ReasonFlux</strong>的层次化特性，通过这种迭代优化得以实现，对于导航复杂推理任务并实现最优解决方案至关重要。总之，<strong>ReasonFlux</strong>通过根据问题复杂性动态配置和调整模板轨迹，实现了有效的问题解决，超越了传统推理方法的局限性，提供了一个更高效和强大的推理框架。</p>
<h3 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h3><p>直接看图就好，总结下来就是赢赢赢！</p>
<p><img src="https://cdn.jsdelivr.net/gh/1-pluto1/blog_imgs/20250511125454875.png" alt="image.png"></p>
<p><img src="https://cdn.jsdelivr.net/gh/1-pluto1/blog_imgs/20250511125507308.png" alt="image.png"></p>
<p><img src="https://cdn.jsdelivr.net/gh/1-pluto1/blog_imgs/20250511125513063.png" alt="image.png"></p>
<p><img src="https://cdn.jsdelivr.net/gh/1-pluto1/blog_imgs/20250511125519571.png" alt="image.png"></p>
<p><img src="https://cdn.jsdelivr.net/gh/1-pluto1/blog_imgs/20250511125525332.png" alt="image.png"></p>
<h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>在这项工作中，我们提出了ReasonFlux，一种新的分层LLM推理框架，它自适应地扩展基本和必要的思维模板，以简化复杂推理的搜索空间，并在数学推理能力上超越了强大的LLM，如OpenAI o1-preview和DeepSeek V3。我们引入了一个结构化和紧凑的思维模板库、思维模板轨迹上的分层强化学习以及一个全新的推理扩展系统。在不同具有挑战性的数学基准上的广泛实验证明了ReasonFlux的优越性。我们还揭示了一些关键发现，包括我们模板增强推理的扩展规律，以及ReasonFlux在探索-利用权衡上相较于以往推理策略的优越性。</p>
<p><strong>版权声明</strong>：本文为原创，转载请注明出处。</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>ReasonFlux阅读</p><p><a href="http://example.com/2025/05/11/Research/ReasonFlux： Hierarchical LLM Reasoning via Scaling Thought Templates/">http://example.com/2025/05/11/Research/ReasonFlux： Hierarchical LLM Reasoning via Scaling Thought Templates/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><a href="http://example.com"><p>Pluto</p></a></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2025-05-11</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2025-05-31</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a class="icon" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a><a class="icon" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="recommend-area"><div class="recommend-post"><span class="is-size-6 has-text-grey has-mr-7"># 相关文章</span><br><span>  1.<a class="is-size-6" href="/2025/05/31/Research/SUPERCORRECT%EF%BC%9ASUPERVISING%20AND%20CORRECTING%20%20LANGUAGE%20MODELS%20WITH%20ERROR-DRIVEN%20INSIGHTS/" target="_blank">SUPERCORRECT：SUPERVISING AND CORRECTING  LANGUAGE MODELS WITH ERROR-DRIVEN INSIGHTS</a><br></span></div></div><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/social-share.js/1.0.16/css/share.min.css"><div class="social-share"></div><script src="https://cdnjs.loli.net/ajax/libs/social-share.js/1.0.16/js/social-share.min.js"></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="https://cdn.jsdelivr.net/gh/1-pluto1/blog_imgs/123501B00F7AB6589E40FE43E701F8C9.jpg" alt="支付宝"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="https://cdn.jsdelivr.net/gh/1-pluto1/blog_imgs/CD85D593847FE4E01CC8386976FEBE69.jpg" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2025/05/31/Research/SUPERCORRECT%EF%BC%9ASUPERVISING%20AND%20CORRECTING%20%20LANGUAGE%20MODELS%20WITH%20ERROR-DRIVEN%20INSIGHTS/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">SUPERCORRECT：SUPERVISING AND CORRECTING  LANGUAGE MODELS WITH ERROR-DRIVEN INSIGHTS</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2024/09/19/NLP/%E6%89%8B%E6%92%95transformer/"><span class="level-item">手撕transformer</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--><div class="card"><div class="card-content"><div class="title is-5">评论</div><div class="content" id="comment-container"></div><script>var valine = new Valine({
            el: '#comment-container' ,
            notify: false,
            verify: false,
            appId: '21qqhhR0tOxfL1WbwUcK92DR-gzGzoHsz',
            appKey: 'e6qxlPdhLm33xH3N9UZP8Oay',
            placeholder: '留下您的高见！',
            avatar: 'mp',
            avatarForce: false,
            meta: ["nick","mail","link"],
            pageSize: 10,
            visitor: false,
            highlight: true,
            recordIP: false,
            path:'/2025/05/11/Research/ReasonFlux： Hierarchical LLM Reasoning via Scaling Thought Templates/',
            lang:'en',
            enableQQ:true,
            requiredFields:["nick","mail","link"]
        });</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><!--!--><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="https://cdn.jsdelivr.net/gh/1-pluto1/blog_imgs/b_0b65080deefa163507d3aa4c6a7a5e07.jpg" alt="Pluto"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Pluto</p><p class="is-size-6 is-block">All things come to those who wait.</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>四川成都</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives/"><p class="title">23</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories/"><p class="title">8</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags/"><p class="title">5</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/1-pluto1" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/1-pluto1"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="mailto:im.yang.zhao.edu@gmail.com"><i class="fa fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="WeiChat" href="https://cdn.jsdelivr.net/gh/1-pluto1/blog_imgs/443E347C13A787C5F7DB59948B0B130A.png"><i class="fab fa-weixin"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="QQ" href="https://qm.qq.com/q/gSHKiKzt6g"><i class="fab fa-qq"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="zhihu" href="https://www.zhihu.com/people/10-65-19-7"><i class="fab fa-zhihu"></i></a></div><div><hr><p id="hitokoto">:D 一言句子获取中...</p><script type="text/javascript" defer>function getYiyan(){
                                $.getJSON("https://v1.hitokoto.cn/", function (data) {
                                if(data){
                                    $('#hitokoto').html("");
                                    $('#hitokoto').append("<strong style='color: #3273dc;'>"+data.hitokoto+"</strong>"+
                                    "<p>"+"来源《"+data.from+"》</p><p>提供者-"+data.creator+"</p>");
                                }});}
                                $(function (){getYiyan();$('#hitokoto').click(function(){getYiyan();})});</script></div></div></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://leetcode.cn/discuss/post/3141566/ru-he-ke-xue-shua-ti-by-endlesscheng-q3yd/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">LeetCode</span></span><span class="level-right"><span class="level-item tag">leetcode.cn</span></span></a></li><li><a class="level is-mobile" href="https://blog.csdn.net/weixin_73184653?spm=1010.2135.3001.10640" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">CSDN</span></span><span class="level-right"><span class="level-item tag">blog.csdn.net</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><h3 class="menu-label">最新评论</h3><span class="body_hot_comment">加载中，最新评论有1分钟缓存...</span></div></div><div class="card widget"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-05-31T14:06:48.839Z">2025-05-31</time></p><p class="title"><a href="/2025/05/31/%E3%80%90%E4%BF%9D%E5%A7%86%E7%BA%A7%E6%95%99%E7%A8%8B%E3%80%91%E4%BB%8E%E9%9B%B6%E6%90%AD%E5%BB%BA%20Hexo%20%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%EF%BC%9AAmazing%20%E4%B8%BB%E9%A2%98%E3%80%81GitHub%20Pages%20%E9%83%A8%E7%BD%B2%E4%B8%8E%20Github%20actions%20%E8%87%AA%E5%8A%A8%E5%8C%96%EF%BC%8C%E7%BB%93%E5%90%88%20Obsidian%20%E5%AE%9E%E7%8E%B0%E9%AB%98%E6%95%88%E5%88%9B%E4%BD%9C/"> </a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2025/05/31/Research/Buffer%20of%20Thoughts%EF%BC%9AThought-Augmented%20Reasoning%20with%20Large%20Language%20Models/"><img src="https://cdn.jsdelivr.net/gh/1-pluto1/blog_imgs/20250531220408214.png" alt="Buffer of Thoughts：Thought-Augmented Reasoning with Large Language Models"></a></figure><div class="media-content"><p class="date"><time dateTime="2025-05-31T14:03:07.000Z">2025-05-31</time></p><p class="title"><a href="/2025/05/31/Research/Buffer%20of%20Thoughts%EF%BC%9AThought-Augmented%20Reasoning%20with%20Large%20Language%20Models/">Buffer of Thoughts：Thought-Augmented Reasoning with Large Language Models</a></p><p class="categories"><a href="/categories/Research/">Research</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2025/05/31/Research/SUPERCORRECT%EF%BC%9ASUPERVISING%20AND%20CORRECTING%20%20LANGUAGE%20MODELS%20WITH%20ERROR-DRIVEN%20INSIGHTS/"><img src="https://cdn.jsdelivr.net/gh/1-pluto1/blog_imgs/20250531212714676.png" alt="SUPERCORRECT：SUPERVISING AND CORRECTING  LANGUAGE MODELS WITH ERROR-DRIVEN INSIGHTS"></a></figure><div class="media-content"><p class="date"><time dateTime="2025-05-31T13:23:55.000Z">2025-05-31</time></p><p class="title"><a href="/2025/05/31/Research/SUPERCORRECT%EF%BC%9ASUPERVISING%20AND%20CORRECTING%20%20LANGUAGE%20MODELS%20WITH%20ERROR-DRIVEN%20INSIGHTS/">SUPERCORRECT：SUPERVISING AND CORRECTING  LANGUAGE MODELS WITH ERROR-DRIVEN INSIGHTS</a></p><p class="categories"><a href="/categories/research/">research</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2025/05/11/Research/ReasonFlux%EF%BC%9A%20Hierarchical%20LLM%20Reasoning%20via%20Scaling%20Thought%20Templates/"><img src="https://github.com/Gen-Verse/ReasonFlux/raw/main/figs/image.png" alt="ReasonFlux阅读"></a></figure><div class="media-content"><p class="date"><time dateTime="2025-05-10T20:35:40.000Z">2025-05-11</time></p><p class="title"><a href="/2025/05/11/Research/ReasonFlux%EF%BC%9A%20Hierarchical%20LLM%20Reasoning%20via%20Scaling%20Thought%20Templates/">ReasonFlux阅读</a></p><p class="categories"><a href="/categories/research/">research</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2024/09/19/NLP/%E6%89%8B%E6%92%95transformer/"><img src="https://cdn.jsdelivr.net/gh/1-pluto1/blog_imgs/avatar.jpg" alt="手撕transformer"></a></figure><div class="media-content"><p class="date"><time dateTime="2024-09-19T05:14:00.000Z">2024-09-19</time></p><p class="title"><a href="/2024/09/19/NLP/%E6%89%8B%E6%92%95transformer/">手撕transformer</a></p><p class="categories"><a href="/categories/NLP/">NLP</a> / <a href="/categories/NLP/research/">research</a></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/C/"><span class="level-start"><span class="level-item">C++</span></span><span class="level-end"><span class="level-item tag">12</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/C/algorithm/"><span class="level-start"><span class="level-item">algorithm</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li></ul></li><li><a class="level is-mobile is-marginless" href="/categories/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/NLP/research/"><span class="level-start"><span class="level-item">research</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile is-marginless" href="/categories/Research/"><span class="level-start"><span class="level-item">Research</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/algorithm/"><span class="level-start"><span class="level-item">algorithm</span></span><span class="level-end"><span class="level-item tag">6</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/algorithm/C/"><span class="level-start"><span class="level-item">C++</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li></ul></li><li><a class="level is-mobile is-marginless" href="/categories/research/"><span class="level-start"><span class="level-item">research</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2025/05/"><span class="level-start"><span class="level-item">五月 2025</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2024/09/"><span class="level-start"><span class="level-item">九月 2024</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2024/07/"><span class="level-start"><span class="level-item">七月 2024</span></span><span class="level-end"><span class="level-item tag">18</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AE%97%E6%B3%95/"><span class="tag">数据结构算法</span><span class="tag is-grey-lightest">12</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"><span class="tag">编程语言</span><span class="tag is-grey-lightest">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLP/"><span class="tag">NLP</span><span class="tag is-grey-lightest">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LLM/"><span class="tag">LLM</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ReasoningModel/"><span class="tag">ReasoningModel</span><span class="tag is-grey-lightest">3</span></a></div></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">订阅更新</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="订阅"></div></div></form></div></div></div><!--!--><div class="column-right-shadow is-hidden-widescreen"></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="https://cdn.jsdelivr.net/gh/1-pluto1/blog_imgs/b_0b65080deefa163507d3aa4c6a7a5e07.jpg" alt="Pluto&#039;s Blog" height="28"></a><p class="size-small"><span>&copy; 2025 Pluto</span>  Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank">Icarus</a> &amp; <a href="https://github.com/removeif/hexo-theme-amazing" target="_blank">Amazing</a> <br><span>© 版权说明：[本网站所有内容均收集于互联网或自己创作,<br />&nbsp;&nbsp;&nbsp;&nbsp;方便于网友与自己学习交流，如有侵权，请<a href="/message" target="_blank">留言</a>，立即处理]<br /></span><div class="size-small"><span>❤️感谢 <strong><span id="busuanzi_value_site_uv">99+</span></strong> 小伙伴的 <strong><span id="busuanzi_value_site_pv">99+</span></strong> 次光临！❤️</span></div></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/1-pluto1"><i class="fab fa-github"></i></a></p></div><div class="sideMusic"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css"><script src="/js/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script><meting-js style="width: auto;height: 2000px;" server="netease" type="playlist" id="7589308811" theme="#2980b9" loop="all" autoplay="false" order="list" storageName="aplayer-setting" lrctype="0" list-max-height="400px" fixed="true"></meting-js></div></div></div></div></footer><script src="https://cdnjs.loli.net/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" async></script><script>moment.locale("zh-cn");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/lightgallery/1.10.0/js/lightgallery.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.8.1/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/javascript" id="MathJax-script" async>MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      },
      svg: {
        fontCache: 'global'
      },
      chtml: {
        matchFontHeight: false
      }
    };</script><script src="https://cdnjs.loli.net/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js"></script><!--!--><script src="/js/main.js" defer></script><script>$.getScript('/js/comment-issue-data.js',function(){loadIssueData('21qqhhR0tOxfL1WbwUcK92DR-gzGzoHsz','e6qxlPdhLm33xH3N9UZP8Oay','akiya','undefined',true);})</script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script data-pjax src="/js/insight.js" defer></script><script data-pjax>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.js"></script><script type="text/javascript">var pjax = new Pjax({
            elements: "a",//代表点击链接就更新
            selectors: [  //代表要更新的节点
                ".section",
                "title"
            ],
            cache: true,
            cacheBust:false
        })

        function loadBusuanzi(){
        $.getScript("//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js", function () {});
        }

        function loadMathJax() { //加载mathjax
            $.getScript("//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML", function () {
                MathJax.Hub.Config({ tex2jax: { inlineMath: [['$', '$'], ['\(', '\)']] } });
                var math = document.getElementsByClassName("entry-content")[0];
                MathJax.Hub.Queue(["Typeset", MathJax.Hub, math]);
            });
        };

        // 开始 PJAX 执行的函数
        document.addEventListener('pjax:send', function () {
        });
        
        // PJAX 完成之后执行的函数，可以和上面的重载放在一起
        document.addEventListener('pjax:complete', function () {
            $(".section").css({opacity:1});
            if(true){
                $.getScript('/js/comment-issue-data.js',function(){loadIssueData('21qqhhR0tOxfL1WbwUcK92DR-gzGzoHsz','e6qxlPdhLm33xH3N9UZP8Oay','akiya','undefined',true);});
            }
            if(false){
                loadMathJax();
            }
            loadMainJs(jQuery, window.moment, window.ClipboardJS, window.IcarusThemeSettings);
            loadBackTop();
            loadBusuanzi();
            if(typeof loadBanner == 'function'){
                loadBanner();
            }
        });</script></body></html>